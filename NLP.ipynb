{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586e143f-da18-4742-bf39-8761a177adbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "# import gensim\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d50a0b-2626-4be3-9f3b-597be2ef08c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into dataframe\n",
    "df = pd.read_csv('~/NLP/Data/watch_reviews.tsv', sep='\\t', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d5e582-60f1-4d83-94d7-a21096cf3b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff8ab82-3a70-4271-b60b-5facc5480d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a910fc7-3994-4f1d-8a16-f8acc796ea89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove missing value\n",
    "df.dropna(subset=['review_body'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a12ba4-10fa-44e8-be18-fd53377fa399",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19d4639-dac7-4fb8-bb95-e60a5151ec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad825a27-613b-4cb0-8b9d-a70f3b1cf844",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172eec77-11fa-4cb5-8eb7-09689ed4da87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the first 1000 data as our training data\n",
    "data = df.loc[:999, 'review_body'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7617f2-b258-442e-b963-4931d326caa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use nltk's English stopwords.\n",
    "stopwords = nltk.corpus.stopwords.words('english') #stopwords.append(\"n't\")\n",
    "stopwords.append(\"'s\")\n",
    "stopwords.append(\"'m\")\n",
    "stopwords.append(\"br\") #html <br>\n",
    "stopwords.append(\"watch\")\n",
    "\n",
    "print (\"We use \" + str(len(stopwords)) + \" stop-words from nltk library.\")\n",
    "print (stopwords[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7c9ebb-73e5-45df-a6a7-b00799a9f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "# from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# tokenization and stemming\n",
    "def tokenization_and_stemming(text):\n",
    "    tokens = []\n",
    "    # exclude stop words and tokenize the document, generate a list of string \n",
    "    for word in nltk.word_tokenize(text):\n",
    "        if word.lower() not in stopwords:\n",
    "            tokens.append(word.lower())\n",
    "\n",
    "    filtered_tokens = []\n",
    "    \n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if token.isalpha():\n",
    "            filtered_tokens.append(token)\n",
    "            \n",
    "    # stemming\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7049862b-3e4e-467f-9396-180422b41f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenization_and_stemming(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7659a9c6-673f-4eca-ab2c-a6fd5e542222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f77031-817a-4998-bae6-b93551c90c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# define vectorizer parameters\n",
    "# TfidfVectorizer will help us to create tf-idf matrix\n",
    "# max_df : maximum document frequency for the given word\n",
    "# min_df : minimum document frequency for the given word\n",
    "# max_features: maximum number of words\n",
    "# use_idf: if not true, we only calculate tf\n",
    "# stop_words : built-in stop words\n",
    "# tokenizer: how to tokenize the document\n",
    "# ngram_range: (min_value, max_value), eg. (1, 3) means the result will include 1-gram, 2-gram, 3-gram\n",
    "tfidf_model = TfidfVectorizer(max_df=0.99, max_features=1000,\n",
    "                                 min_df=0.01, stop_words='english',\n",
    "                                 use_idf=True, tokenizer=tokenization_and_stemming, ngram_range=(1,1))\n",
    "\n",
    "tfidf_matrix = tfidf_model.fit_transform(data) #fit the vectorizer to synopses\n",
    "\n",
    "print (\"In total, there are \" + str(tfidf_matrix.shape[0]) + \\\n",
    "      \" reviews and \" + str(tfidf_matrix.shape[1]) + \" terms.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a41630-981f-44b2-81b3-bbcc23646c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c7ecfb-f984-40d5-a046-e02868039e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix.toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216d015b-4d31-4595-b5ba-d7bc611170ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee7c047-af0a-4f0f-bba0-eb250ab78367",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(tfidf_matrix.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545550de-96ce-4589-9a5b-2481d3f60b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(tfidf_matrix.todense()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531a958d-5b88-40af-91ce-cb2d7c08e890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K means \n",
    "# 缺点：分类不平均，有些分类比较大，有些比较小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3577b0-b261-4b49-b0c5-697f52a86c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-means clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 5\n",
    "\n",
    "# number of clusters\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "km.fit(tfidf_matrix)\n",
    "\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba51ab3e-e698-4475-b06e-7de3d92d65a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DataFrame films from all of the input files.\n",
    "product = { 'review': df[:1000].review_body, 'cluster': clusters}\n",
    "frame = pd.DataFrame(product, columns = ['review', 'cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90475564-e6ac-4ea9-8c57-f82965724a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74298bb8-ba63-424a-aade-ca3d122a9695",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Number of reviews included in each cluster:\")\n",
    "frame['cluster'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae1233f-02ae-45e3-8c9a-d7ee5ba849e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "km.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea22f2d-c645-439a-b591-daefa93a5a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "km.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010e4af2-78ee-45f7-a1b1-acea3cdbbe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use LDA for clustering\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(n_components=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395a2f3f-c23a-4866-8092-322a0d55f023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document topic matrix for tfidf_matrix_lda\n",
    "lda_output = lda.fit_transform(tfidf_matrix)\n",
    "print(lda_output.shape)\n",
    "print(lda_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e862ed22-66c7-47af-997b-184b6840113a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topics and words matrix\n",
    "topic_word = lda.components_\n",
    "print(topic_word.shape)\n",
    "print(topic_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccf5e5b-0339-4fd8-a6b2-c765451ae4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column names\n",
    "topic_names = [\"Topic\" + str(i) for i in range(lda.n_components)]\n",
    "print(topic_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a8daf2-0b18-46e4-8a26-d52039242289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index names\n",
    "doc_names = [\"Doc\" + str(i) for i in range(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7b6510-239b-4015-b6c2-ad57a5ce7d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns=topic_names, index=doc_names)\n",
    "\n",
    "# get dominant topic for each document\n",
    "topic = np.argmax(df_document_topic.values, axis=1)\n",
    "df_document_topic['topic'] = topic\n",
    "\n",
    "df_document_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd23556-fb58-400f-aead-09f81b8045f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_document_topic['topic'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25891da5-fc39-41b8-bbd2-7f45eb490973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic-word matrix\n",
    "df_topic_words = pd.DataFrame(lda.components_)\n",
    "\n",
    "# Column names\n",
    "df_topic_words.columns = tfidf_model.get_feature_names_out()\n",
    "\n",
    "# Index names\n",
    "df_topic_words.index = topic_names\n",
    "\n",
    "df_topic_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de50ab24-110f-4c70-b741-8444b62dddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print top n keywords for each topic\n",
    "def print_topic_words(tfidf_model, lda_model, n_words):\n",
    "    words = np.array(tfidf_model.get_feature_names_out())\n",
    "    topic_words = []\n",
    "    # for each topic, we have words weight\n",
    "    for topic_words_weights in lda_model.components_:\n",
    "        top_words = topic_words_weights.argsort()[::-1][:n_words]\n",
    "        topic_words.append(words.take(top_words))\n",
    "    return topic_words\n",
    "\n",
    "topic_keywords = print_topic_words(tfidf_model=tfidf_model, lda_model=lda, n_words=15)        \n",
    "\n",
    "df_topic_words = pd.DataFrame(topic_keywords)\n",
    "df_topic_words.columns = ['Word '+str(i) for i in range(df_topic_words.shape[1])]\n",
    "df_topic_words.index = ['Topic '+str(i) for i in range(df_topic_words.shape[0])]\n",
    "df_topic_words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
